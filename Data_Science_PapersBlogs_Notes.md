## Medium:

#### Listing Embeddings in Search Ranking

- Link: https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e
- Description: The idea is to create/train vector representations (Embeddings) of available accomodations in Airbnb that will allow to measure similarities between them and eventually to present similar to the users (Similar Listings) or use as the extra features to Search Ranking model.
- Technologies: NN (to train with backprop embeddings)
- More:  Given this data set, the aim is to learn a 32-dimensional real-valued representation V(L_{i}) $\in R^{32}$  of each unique listing Li, such that similar listings lie nearby in the embedding space. The *Negative Sampling* techinique is used to train embeddings. Starting with initially random vectors (embeddings), and proceeds to update them via stochastic gradient descent by reading through search sessions in a sliding window manner. At each step the vector of the central listing is updated by pushing it closer to vectors of positive context listings: listings that were clicked by the same user before and after central listing, within a window of length m (m = 5), and pushing it away from negative context listings: randomly sampled listings (as chances are these are not related to the central listing).  Two modification were also made for this approach:
    - using *Booked Listing as Global Context*: The sessions that end with the user booking the listing (purple listing) are used to adapt the optimization such that at each step we predict not only the neighboring clicked listings but also the eventually booked listing as well.
    - adapting to *Congregated Search*: Users of online travel booking sites typically search only within a single market (same geo location). As a consequence, for a given central listing, the positive context listings mostly consist of listings from the same market, while the negative context listings mostly consists of listings that are not from the same market as they are sampled randomly from entire listing vocabulary. This imbalance leads to learning sub-optimal within-market similarities. To address this issue is proposed to add a set of random negatives Dmn, sampled from the market of the central.
    
    For new accomodations *Cold Start Embeddings* authors find 3 geographically closest listings that do have embeddings, and are of same listing type and price range as the new listing, and calculate their mean vector. The offline evaluation is done by taking the most recently clicked listing and the listing candidates that need to be ranked, which contain the listing that user eventually booked. By calculating cosine similarities between embeddings of the clicked listing and the candidate listings we can rank the candidates and observe the rank position of the booked listing. For the *Search Ranking* where the aim is to show to the guest more listings that are similar to the ones we think they liked since starting the search session and fewer listings similar to the ones we think they did not like. To achieve this, for each user authors collected and maintain in real-time (using Kafka) two sets of short-term history events: **Hc** - set of listing ids that user clicked in last 2 weeks and **Hs** - set of listing ids that user skipped in last 2 weeks, where we define skipped listings as ones that were ranked high but skipped by user in favor of a click on a lower positioned listing. These two similarity measures were next introduced as additional signal that our Search Ranking Machine Learning model considers when ranking candidate listings.



## Trivago:

#### Machine Learning and Bathtubs - How Small Visual Changes Improve User Experience" 
	
- Link: https://tech.trivago.com/2019/08/21/machine-learning-and-bathtubs-how-small-visual-changes-improve-user-experience/	
- Description: The idea is to adjust the main images of hotels to reflect the user intent coming from SEM ads containing spa concepts (concept-based main images)
- Technologies: AWS stack for pipelines, RNN, CNN with transfer learning. 
- More: Automated (with CV) image labeling of Trivago 100+ millions active images for Spa & Wellness. For training some public data has been used along with existing handpicked image tags from our trivago hoteliers. A questionnaires have been prepared based on Amazon Mechanical Turk to align the images semantically. The resulting dataset had 2,000 images for each of the categories of "Sauna", "Pool", "Gym", "Yoga", "Hot-tub" and "Massage". Five different CNN architectures (InceptionV3, VGG16, Xception, ResNet50, InceptionResnetV2) were evaluated with VGG16 chosen as final model. Precision was used as evaluation metric (to min False Positives). To deal with the images that had to be negated (out all classes that are beyond this concept) two additional (unbalanced) classes were introduced "Bedroom" and "Non-Spa". An average  Precision and Recall  of ~85% and ~89% for the individual Spa & Wellness classes.
